{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DiploDatos/AprendizajePorRefuerzos/blob/master/lab_1_intro_rl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4spynKMzGS4t"
   },
   "source": [
    "# Notebook 1: Introducción al aprendizaje por refuerzos\n",
    "\n",
    "Curso Aprendizaje por Refuerzos, Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones\n",
    "\n",
    "FaMAF, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mlW-PAFGS4z"
   },
   "source": [
    "## Introducción\n",
    "\n",
    "En el siguiente notebook se muestra cómo ejecutar agentes de aprendizaje por refuerzos, los cuáles son necesarios para realizar este Lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repaso rápido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "* Recompensa: señal $r$ recibida desde el entorno que recompensa o castiga el agente según su desempeño con respecto al objetivo de la tarea.\n",
    "\n",
    "* Valor: función $v_\\pi (s)$ que establece cuánto el agente espera percibir de recompensa al seguir la política $\\pi$ partiendo desde el estado $s$. También se la suele expresar como $Q_\\pi(s,a)$, indicando cuánto el agente espera percibir siguiendo la política $\\pi$ partiendo desde el estado $s$ y siguiendo la acción $a$.\n",
    "\n",
    "* Política: función $\\pi(s) \\to a$ que mapea un estado a una acción. Se suele expresar como probabilidad de elegir la acción $\\pi(a \\mid s)$. La política $\\epsilon$-greedy, en donde $\\epsilon$ es la probabilidad de exploración (normalmente menor que la probabilidad de explotación) está dada por\n",
    "$$\\pi(a \\mid s) = 1 - \\epsilon$$ si $a$ es la mejor acción, caso contrario $$\\pi(a \\mid s) = \\epsilon$$\n",
    "\n",
    "Por otra parte, en la política Softmax, no se busca la acción con máxima probabilidad sino que se computa la probabilidad de cada una mediante la función Softmax y se realiza un sorteo entre ellas pesado por la misma. Así, para cada acción $a$, $$\\pi(a \\mid s) = \\frac{e^{Q(s,a)/\\tau}}{\\sum_{\\widetilde{a} \\in A}e^{Q(s,\\widetilde{a})/\\tau}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "En este notebook vemos dos algoritmos para actualizar la función de valor (y, por lo tanto, la política de selección de acciones):\n",
    "\n",
    "* Actualización por SARSA (on-policy).\n",
    "\n",
    "$$Q(s,a) \\gets Q(s,a) + \\alpha (r + \\gamma Q(s',a') - Q(s,a))$$\n",
    "\n",
    "Algoritmo completo (a modo de referencia):\n",
    "\n",
    "![Algoritmo SARSA](images/sarsa.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Actualización por Q-Learning (off-policy)\n",
    "\n",
    "$$Q(s,a) \\gets Q(s,a) + \\alpha (r + \\gamma \\arg\\max_{a'} Q(s',a') - Q(s,a))$$\n",
    "\n",
    "Algoritmo completo (a modo de referencia):\n",
    "\n",
    "![Algoritmo Q-Learning](images/q_learning.png)\n",
    "\n",
    "Fuente de las imágenes: capítulo 6 de [Reinforcement Learning: An Introduction](http://www.incompleteideas.net/book/the-book.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7BO38B6GS4z"
   },
   "source": [
    "## Librería a usar: Librería OpenAI Gym\n",
    "\n",
    "[OpenAI Gym](https://gym.openai.com/) (Brockman et. al., 2016) es una librería de OpenAI que ofrece entornos y una interfaz estándar con la cuál probar nuestros agentes. Su objetivo es proveer benchmarks unificados para ver el desempeño de algoritmos en el entorno y así poder saber con facilidad cómo es su desempeño comparado con los demás. Parte de la siguiente sección está basada en la [documentación oficial de OpenAI](https://gym.openai.com/docs/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YY7NVUdpGS40"
   },
   "source": [
    "La interfaz principal de los ambientes de gym es la interfaz Env. La misma posee tres métodos principales:\n",
    "\n",
    "```reset(self)``` : Reinicia el estado del entorno, a su estado inicial, devolviendo una observación de dicho estado.\n",
    "\n",
    "* ```step(self, action)``` : \"Avanza\" un timestep del ambiente. Devuelve: ```observation, reward, done, info```.\n",
    "\n",
    "* ```render(self)``` : Muestra en pantalla una parte del ambiente.\n",
    "\n",
    "* ```close(self)``` : Finaliza con la instancia del agente.\n",
    "\n",
    "* ```seed(self)``` : Establece la semilla aleatoria del generador de números aleatorios del presente entorno.\n",
    "\n",
    "\n",
    "Por otra parte, cada entorno posee los siguientes tres atributos principales:\n",
    "\n",
    "* ```action_space``` : El objeto de tipo Space correspondiente al espacio de acciones válidas.\n",
    "\n",
    "* ```observation_space``` : El objeto de tipo Space correspondiente a todos los rangos posibles de observaciones.\n",
    "\n",
    "* ```reward_range``` : Tupla que contiene los valores mínimo y máximo de recompensa posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTMpnXzcGS40"
   },
   "source": [
    "Algunas de las ejecuciones contienen videos. Para poder verlos se necesita previamente instalar la librería ffmpeg; para instalarla desde Linux ejecutar en consola\n",
    "\n",
    "```sudo apt-get install ffmpeg```\n",
    "\n",
    "\n",
    "desde Windows descargarla desde\n",
    "\n",
    "[https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)\n",
    "\n",
    "(Nota: las animaciones son a modo ilustrativo, si no se desea instalar la librería se puede directamente eliminar la línea de código donde se llama al método ``env.render(mode='human')``)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZDT_O0UGS40"
   },
   "source": [
    "Código básico de importación y funciones de graficación (no modificar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "hideCode": true,
    "id": "5jUjOuhYGS42",
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Código básico de graficación (no modificar)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import gym\n",
    "\n",
    "def plot_reward_per_episode(reward_ep):\n",
    "\n",
    "    episode_rewards = np.array(reward_ep)\n",
    "\n",
    "    # se suaviza la curva de convergencia\n",
    "    episode_number = np.linspace(1, len(episode_rewards) + 1, len(episode_rewards) + 1)\n",
    "    acumulated_rewards = np.cumsum(episode_rewards)\n",
    "\n",
    "    reward_per_episode = [acumulated_rewards[i] / episode_number[i] for i in range(len(acumulated_rewards))]\n",
    "\n",
    "    plt.plot(reward_per_episode)\n",
    "    plt.title('Recompensa acumulada por episodio')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_steps_per_episode(timesteps_ep):\n",
    "    # se muestra la curva de aprendizaje de los pasos por episodio\n",
    "    episode_steps = np.array(timesteps_ep)\n",
    "    plt.plot(np.array(range(0, len(episode_steps))), episode_steps)\n",
    "    plt.title('Pasos (timesteps) por episodio')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_steps_per_episode_smooth(timesteps_ep):\n",
    "    episode_steps = np.array(timesteps_ep)\n",
    "\n",
    "    # se suaviza la curva de aprendizaje\n",
    "    episode_number = np.linspace(1, len(episode_steps) + 1, len(episode_steps) + 1)\n",
    "    acumulated_steps = np.cumsum(episode_steps)\n",
    "\n",
    "    steps_per_episode = [acumulated_steps[i] / episode_number[i] for i in range(len(acumulated_steps))]\n",
    "\n",
    "    plt.plot(steps_per_episode)\n",
    "    plt.title('Pasos (timesteps) acumulados por episodio')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def draw_value_matrix(q):\n",
    "\n",
    "    n_rows = 4\n",
    "    n_columns = 12\n",
    "    n_actions = 4\n",
    "\n",
    "    # se procede con los cálculos previos a la graficación de la matriz de valor\n",
    "    q_value_matrix = np.empty((n_rows, n_columns))\n",
    "    for row in range(n_rows):\n",
    "        for column in range(n_columns):\n",
    "\n",
    "            state_values = []\n",
    "\n",
    "            for action in range(n_actions):\n",
    "                state_values.append(q.get((row * n_columns + column, action), -100))\n",
    "\n",
    "            maximum_value = max(state_values)  # determinamos la acción que arroja máximo valor\n",
    "\n",
    "\n",
    "            q_value_matrix[row, column] = maximum_value\n",
    "\n",
    "    # el valor del estado objetivo se asigna en -1 (reward recibido al llegar) para que se coloree de forma apropiada\n",
    "    q_value_matrix[3, 11] = -1\n",
    "\n",
    "    # se grafica la matriz de valor\n",
    "    plt.imshow(q_value_matrix, cmap=plt.cm.RdYlGn)\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "\n",
    "    for row, column in itertools.product(range(q_value_matrix.shape[0]), range(q_value_matrix.shape[1])):\n",
    "\n",
    "        left_action = q.get((row * n_columns + column, 3), -1000)\n",
    "        down_action = q.get((row * n_columns + column, 2), -1000)\n",
    "        right_action = q.get((row * n_columns + column, 1), -1000)\n",
    "        up_action = q.get((row * n_columns + column, 0), -1000)\n",
    "\n",
    "        arrow_direction = 'D'\n",
    "        best_action = down_action\n",
    "\n",
    "        if best_action < right_action:\n",
    "            arrow_direction = 'R'\n",
    "            best_action = right_action\n",
    "        if best_action < left_action:\n",
    "            arrow_direction = 'L'\n",
    "            best_action = left_action\n",
    "        if best_action < up_action:\n",
    "            arrow_direction = 'U'\n",
    "            best_action = up_action\n",
    "        if best_action == -1:\n",
    "            arrow_direction = ''\n",
    "\n",
    "        # notar que column, row están invertidos en orden en la línea de abajo porque representan a x,y del plot\n",
    "        plt.text(column, row, arrow_direction, horizontalalignment=\"center\")\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    print('\\n Matriz de mejor acción-valor (en números): \\n\\n', q_value_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJ1y2VTGGS42"
   },
   "source": [
    "Ejemplo: agente CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YPkxgtSiGS43"
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('c:/users/arrua/appdata/roaming/python/python39/site-packages')\n",
    "\n",
    "import gym\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "# no es posible mostrar videos de ejecución del agente desde Colab\n",
    "if not IN_COLAB:\n",
    "\n",
    "    env = gym.make('CartPole-v0')\n",
    "    env.reset()\n",
    "    for _ in range(500):\n",
    "        env.render(mode='human')\n",
    "        observation, reward, done, info = env.step(env.action_space.sample()) # se ejecuta una acción aleatoria\n",
    "        if done:\n",
    "            env.reset()\n",
    "    env.close()\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ_A87JtGS43"
   },
   "source": [
    "Ejemplo: agente Mountain Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QHDTjlpEGS43"
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    env = gym.make('MountainCar-v0')\n",
    "    observation = env.reset()\n",
    "    for t in range(500):\n",
    "        env.render(mode='human')\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "    env.close()\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[43m \u001b[0m: |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Taxi-v3\").env\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "|\u001b[43m \u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n",
      "Action Space Discrete(6)\n",
      "State Space Discrete(500)\n"
     ]
    }
   ],
   "source": [
    "env.reset() # reset environment to a new, random state\n",
    "env.render()\n",
    "\n",
    "print(\"Action Space {}\".format(env.action_space))\n",
    "print(\"State Space {}\".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 328\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = env.encode(3, 1, 2, 0) # (taxi row, taxi column, passenger index, destination index)\n",
    "print(\"State:\", state)\n",
    "\n",
    "env.s = state\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 428, -1, False)],\n",
       " 1: [(1.0, 228, -1, False)],\n",
       " 2: [(1.0, 348, -1, False)],\n",
       " 3: [(1.0, 328, -1, False)],\n",
       " 4: [(1.0, 328, -10, False)],\n",
       " 5: [(1.0, 328, -10, False)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[328]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 4396\n",
      "Penalties incurred: 1424\n"
     ]
    }
   ],
   "source": [
    "env.s = 328  # set environment to illustration's state\n",
    "\n",
    "epochs = 0\n",
    "penalties, reward = 0, 0\n",
    "\n",
    "frames = [] # for animation\n",
    "\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "\n",
    "    if reward == -10:\n",
    "        penalties += 1\n",
    "    \n",
    "    # Put each rendered frame into dict for animation\n",
    "    frames.append({\n",
    "        'frame': env.render(mode='ansi'),\n",
    "        'state': state,\n",
    "        'action': action,\n",
    "        'reward': reward\n",
    "        }\n",
    "    )\n",
    "\n",
    "    epochs += 1\n",
    "    \n",
    "    \n",
    "print(\"Timesteps taken: {}\".format(epochs))\n",
    "print(\"Penalties incurred: {}\".format(penalties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "\n",
      "Timestep: 4396\n",
      "State: 0\n",
      "Action: 5\n",
      "Reward: 20\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "def print_frames(frames):\n",
    "    for i, frame in enumerate(frames):\n",
    "        clear_output(wait=True)\n",
    "        print(frame['frame'])\n",
    "        print(f\"Timestep: {i + 1}\")\n",
    "        print(f\"State: {frame['state']}\")\n",
    "        print(f\"Action: {frame['action']}\")\n",
    "        print(f\"Reward: {frame['reward']}\")\n",
    "        sleep(.1)\n",
    "        \n",
    "print_frames(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "q_table = np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100000\n",
      "Training finished.\n",
      "\n",
      "Wall time: 33.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"Training the agent\"\"\"\n",
    "\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1\n",
    "\n",
    "# For plotting metrics\n",
    "all_epochs = []\n",
    "all_penalties = []\n",
    "\n",
    "for i in range(1, 100001):\n",
    "    state = env.reset()\n",
    "\n",
    "    epochs, penalties, reward, = 0, 0, 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample() # Explore action space\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) # Exploit learned values\n",
    "\n",
    "        next_state, reward, done, info = env.step(action) \n",
    "        \n",
    "        old_value = q_table[state, action]\n",
    "        next_max = np.max(q_table[next_state])\n",
    "        \n",
    "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "        q_table[state, action] = new_value\n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        state = next_state\n",
    "        epochs += 1\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Episode: {i}\")\n",
    "\n",
    "print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.40560476,  -2.27325184,  -2.41423776,  -2.35601721,\n",
       "       -10.52751099, -10.67449282])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[328]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrdYut6HGS44"
   },
   "source": [
    "## Ejemplo 1: The Cliff. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6bNIHCQGS44"
   },
   "source": [
    "![](https://github.com/GIDISIA/RLDiplodatos/blob/master/images/cliffwalking.png?raw=1)\n",
    "\n",
    "donde S= starting point, G= goal\n",
    "\n",
    "(imagen de Sutton y Barto, 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYvKmWcsGS44"
   },
   "source": [
    "Descripción del entorno:\n",
    "\n",
    "Acciones:\n",
    "\n",
    "* $\\uparrow$ - Arriba\n",
    "* $\\downarrow$ - Abajo\n",
    "* $\\rightarrow$ - Derecha\n",
    "* $\\leftarrow$ - Izquierda\n",
    "\n",
    "Función de recompensa:\n",
    "\n",
    "* $-1$ en todos los demás estados \n",
    "* $-100$ en el acantilado\n",
    "\n",
    "Nota: caer en el acantilado devuelve al agente al estado inicial en un mismo episodio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ2D3hokGS44"
   },
   "source": [
    "Vemos los bloques básicos de nuestro agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q[0,3]=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q[1,2]=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q[2,2]=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  5.],\n",
       "       [ 0.,  0., 10.,  0.],\n",
       "       [ 0.,  0., 10.,  0.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_q=[]\n",
    "for i in range(0,Q.shape[0],1):\n",
    "    for j in range(0,Q.shape[1],1):\n",
    "        if Q[i,j]==np.max(Q):\n",
    "            max_q.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_Valor=[2,10,3,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_q=[]\n",
    "for i in range(0,len(q_Valor),1):\n",
    "    if q_Valor[i]==np.max(q_Valor):\n",
    "            max_q.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKgvYRiOGS44"
   },
   "source": [
    "Definimos el método de elección de acciones. En este caso el mismo utiliza la política de exploración $\\epsilon$-greedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "T8XHFSZiGS44"
   },
   "outputs": [],
   "source": [
    "def choose_action(state):\n",
    "    \"\"\"\n",
    "    Chooses an action according to the learning previously performed \n",
    "    using an epsilon-greedy exploration policy\n",
    "    \"\"\"\n",
    "    q_values = q[state,:]  # ej: para 4 acciones inicializa en [0,0,0,0]\n",
    "    \n",
    "    max_q =[]\n",
    "\n",
    "    if random_state.uniform() < epsilon:  # sorteamos un número: es menor a épsilon?\n",
    "        return random_state.choice(actions)  # sí: se selecciona una acción aleatoria\n",
    "\n",
    "   \n",
    "    for i in range(0,len(q_values),1):\n",
    "        if q_values[i]==np.max(q_values):\n",
    "            max_q.append(i)\n",
    "    \n",
    "    count = len(max_q)\n",
    "\n",
    "    \n",
    "    # hay más de un máximo valor de estado-acción?\n",
    "    if count > 1:\n",
    "        # sí: seleccionamos uno de ellos aleatoriamente\n",
    "#         best = [i for i in range(len(actions)) if q_values[i] == max_q]\n",
    "        i = random_state.choice(max_q)\n",
    "    else:\n",
    "        # no: seleccionamos el máximo valor de estado-acción\n",
    "        i = max_q[0]\n",
    "\n",
    "    \n",
    "    return actions[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH6yG3UNGS45"
   },
   "source": [
    "Definimos el esqueleto del método learn, el cuál toma una transición y cambia el dict de los valores de Q de acuerdo a algún algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5RgIJcbGGS45"
   },
   "outputs": [],
   "source": [
    "def learn_sarsa(state, action, reward, next_state, next_action):\n",
    "     \"\"\"\n",
    "    Performs a SARSA update for a given state transition\n",
    "    \"\"\"\n",
    "\n",
    "    predict = q.get((state,action),0)\n",
    "\n",
    "    target = reward + gamma * q.get((next_state, next_action),0)\n",
    "\n",
    "    q[state, action] = predict + alpha * (target - predict)\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_q(state, action, reward, next_state, next_action):\n",
    "    q[state, action] = q[state, action] + alpha * (reward + gamma * np.max(q[next_state, :])- q[state, action])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xrOq-6jGS45"
   },
   "source": [
    "Finalmente, definimos el método principal de iteraciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "EatmEq8XGS45"
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    \"\"\"\n",
    "    Runs the reinforcement learning agent with a given configuration.\n",
    "    \"\"\"\n",
    "    timesteps_of_episode = []  # registro de la cantidad de pasos que le llevó en cada episodio\n",
    "    reward_of_episode = []  # cantidad de recompensa que recibió el agente en cada episodio\n",
    "\n",
    "    for i_episode in range(episodes_to_run):\n",
    "        # se ejecuta una instancia del agente hasta que el mismo llega a la salida\n",
    "        # o tarda más de 2000 pasos\n",
    "\n",
    "        # reinicia el ambiente, obteniendo el estado inicial del mismo\n",
    "        state = env.reset()\n",
    "\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        t = 0\n",
    "\n",
    "        # elige una acción basado en el estado actual\n",
    "        action = choose_action(state)\n",
    "        \n",
    "        while not done:\n",
    "\n",
    "            # el agente ejecuta la acción elegida y obtiene los resultados\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            next_action = choose_action(next_state)\n",
    "            \n",
    "\n",
    "            episode_reward += reward\n",
    "            learn_qq(state, action, reward, next_state, next_action)\n",
    "\n",
    "            if not done and t < 2000:  # if the algorithm does not converge, it stops after 2000 timesteps\n",
    "                state = next_state\n",
    "                action = next_action\n",
    "            else:\n",
    "                # el algoritmo no ha podido llegar a la meta antes de dar 2000 pasos\n",
    "                done = True  # se establece manualmente la bandera done\n",
    "                timesteps_of_episode = np.append(timesteps_of_episode, [int(t + 1)])\n",
    "                reward_of_episode = np.append(reward_of_episode, max(episode_reward, -100))\n",
    "\n",
    "            t += 1\n",
    "\n",
    "    return reward_of_episode.mean(), timesteps_of_episode, reward_of_episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQqcI9RTGS46"
   },
   "source": [
    "Definidos los métodos básicos, procedemos a instanciar a nuestro agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "JWE7qhNvGS46"
   },
   "outputs": [],
   "source": [
    "# se crea el diccionario que contendrá los valores de Q para cada tupla (estado, acción)\n",
    "q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "\n",
    "# definimos sus híper-parámetros básicos\n",
    "\n",
    "alpha = 0.5\n",
    "gamma = 1\n",
    "epsilon = 0.1\n",
    "tau = 25\n",
    "\n",
    "episodes_to_run = 500\n",
    "\n",
    "env = gym.make(\"CliffWalking-v0\")\n",
    "actions = range(env.action_space.n)\n",
    "\n",
    "# se declara una semilla aleatoria\n",
    "random_state = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nBgpEltGS47"
   },
   "source": [
    "Ya instanciado, ejecutamos nuestro agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "r_Y6EMN3GS47",
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_steps_per_episode, timesteps_ep, reward_ep = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -12.98013623,  -12.45088658,  -12.39939058,  -12.39235152],\n",
       "       [ -11.72587654,  -11.67293392,  -12.28161764,  -11.94616272],\n",
       "       [ -11.26806752,  -10.81071457,  -11.2637506 ,  -11.48321635],\n",
       "       [  -9.92499467,   -9.99926045,  -10.32441927,  -10.677473  ],\n",
       "       [  -9.41249375,   -9.17400406,   -9.10703266,   -9.63442639],\n",
       "       [  -8.25901013,   -8.29062156,   -8.60338427,   -9.12706025],\n",
       "       [  -7.70366962,   -7.45007658,   -7.58711808,   -7.75279399],\n",
       "       [  -6.6518122 ,   -6.64627386,   -6.73480648,   -7.14377359],\n",
       "       [  -6.34505538,   -5.81117907,   -5.78033957,   -6.17483656],\n",
       "       [  -5.1851649 ,   -4.90210955,   -4.94823648,   -5.35335463],\n",
       "       [  -4.10498047,   -3.96596973,   -3.95755466,   -4.87104747],\n",
       "       [  -3.52427292,   -3.69227511,   -2.99931885,   -3.87385853],\n",
       "       [ -12.93599468,  -12.87201958,  -12.93580785,  -13.47258772],\n",
       "       [ -12.08103943,  -11.95108138,  -11.96179008,  -12.82535571],\n",
       "       [ -11.06812387,  -10.98381113,  -10.98740941,  -11.37345907],\n",
       "       [ -10.08545553,   -9.997261  ,   -9.99487077,  -10.03528532],\n",
       "       [  -9.30063595,   -8.99921666,   -8.99955445,   -9.18240052],\n",
       "       [  -8.35523736,   -7.99976391,   -7.99986682,   -8.09927521],\n",
       "       [  -7.68053178,   -6.99990776,   -6.99993291,   -7.02503797],\n",
       "       [  -6.79231418,   -5.99997918,   -5.99998462,   -7.15110955],\n",
       "       [  -5.89573891,   -4.99999828,   -4.99999778,   -6.36340784],\n",
       "       [  -5.64066213,   -3.99999932,   -3.99999955,   -5.79851942],\n",
       "       [  -3.35546875,   -2.99999998,   -2.99999998,   -3.24609375],\n",
       "       [  -3.74659427,   -2.93060873,   -2.        ,   -3.84100472],\n",
       "       [ -13.80383041,  -12.        ,  -13.99999452,  -12.99999298],\n",
       "       [ -12.86296249,  -11.        , -112.9999811 ,  -12.99997707],\n",
       "       [ -11.84429659,  -10.        , -112.99996667,  -11.9999999 ],\n",
       "       [ -10.98575006,   -9.        , -112.99542332,  -10.99996637],\n",
       "       [  -9.99629846,   -8.        , -112.99803697,   -9.99999267],\n",
       "       [  -8.99860657,   -7.        , -112.99992963,   -8.99999315],\n",
       "       [  -7.99335641,   -6.        , -112.98924089,   -7.99999652],\n",
       "       [  -6.99958276,   -5.        , -112.97796829,   -6.99953163],\n",
       "       [  -5.99999282,   -4.        , -112.9995054 ,   -5.99951541],\n",
       "       [  -4.99762289,   -3.        , -112.9995271 ,   -4.99451002],\n",
       "       [  -3.99993894,   -2.        , -112.99611694,   -3.99998012],\n",
       "       [  -2.99997329,   -1.99992371,   -1.        ,   -2.98730469],\n",
       "       [ -13.        , -112.99992417,  -13.9999727 ,  -13.99999776],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgNpJUV9GS47"
   },
   "source": [
    "### Análisis de la ejecución del agente\n",
    "\n",
    "#### Análisis de convergencia\n",
    "\n",
    "A diferencia de lo que sucede en el aprendizaje supervisado, en el aprendizaje por refuerzos el rendimiento se evalúa por una función específica que es la función de recompensa. En la práctica, la función de recompensa puede ser externa (y provista por el entorno) o bien puede ser una función creada por diseño (a modo de dirigir el agente hacia lo que por diseño se considera mejor, en nuestro ejemplo podría ser con una recompensa de $+1$ cada vez que el agente llega al estado objetivo). Esto se conoce como *reward shaping*, y hay que tener mucho cuidado con los posibles efectos secundarios de su uso.\n",
    "\n",
    "Como el objetivo de RL es maximizar la recompensa obtenida, es posible utilizar la información sobre la obtención de la recompensas en cada time-step o episodio para evaluar el rendimiento parcial del agente (esto depende mucho de la particularidad de la distribución de la recompensa para el problema tratado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiciXUMeGS47"
   },
   "source": [
    "Para analizar la ejecución del agente, vamos a ver cómo se desempeñó el mismo en dos curvas:\n",
    "\n",
    "* Recompensa obtenida en cada episodio: nos dirá cuánta recompensa obtuvo el agente sumando cada una de recompensas individuales de cada episodio. Con esta medida podremos tener una noción de cómo se desempeñó esquivando el acantilado y llegando lo antes posible a la meta.\n",
    "\n",
    "* Pasos transcurridos en cada episodio: indicará cuántos pasos le ha llevado al agente la ejecución del episodio.\n",
    "\n",
    "Se estila suavizar ambas curvas para apreciar mejor su progresión (aunque a veces suele analizarse la curva de pasos por episodio sin suavizar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQKMwQ2mGS47"
   },
   "source": [
    "Veamos recompensa por episodio (recordar que en este entorno cada paso otorga una recompensa de $-1$ excepto al caer al acantilado, donde la recompensa es de $-100$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "SsDunXlHGS47",
    "outputId": "a638f75b-418f-4daa-fe02-89cb03f770ab"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_reward_per_episode(reward_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjznrgIeGS48"
   },
   "source": [
    "Veamos pasos por episodio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "7AaVw7EEGS48",
    "outputId": "41571be8-f993-4ff4-eb2c-5557d272cb10"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_steps_per_episode(timesteps_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BB8NDDhGS49"
   },
   "source": [
    "Suavizando..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "NaAXjfdKGS49",
    "outputId": "ee8a7ef1-4104-45b1-c555-d80dd92a12ed"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_steps_per_episode_smooth(timesteps_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI7pxgtoGS49"
   },
   "source": [
    "#### Análisis de matriz de acción-valor y política óptima\n",
    "\n",
    "Siendo que este es un ejemplo tabular y de pocos estados / acciones, es posible realizar un análisis de convergencia desde otro punto de vista: desde el valor de la función $Q(s,a)$ para la mejor acción de cada estado, al finalizar el entrenamiento del agente, (sería la acción que el agente ejecutaría en cada estado bajo una política *greedy*). Ambos nos brindarán información sobre la convergencia alcanzada por el agente.\n",
    "\n",
    "Tener en cuenta que este análisis se hace principalmente con fines educativos, para entornos más complejos el mismo puede no ser factible. En tales casos, un análisis alternativo podría consistir en hacer que el agente ejecute su política para la que fue entrenado, para hacer una evaluación a partir del comportamiento del mismo (esto último sería el *test de la política*, frente al *entrenamiento de la política* previo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "rMpKRT2NGS4-",
    "outputId": "5c304631-abee-456a-adfd-28b19a00cb7d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Matriz de mejor acción-valor (en números): \n",
      "\n",
      " [[-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.]\n",
      " [-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.]\n",
      " [-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.]\n",
      " [-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.   -1.]]\n"
     ]
    }
   ],
   "source": [
    "draw_value_matrix(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ce50gtxcGS4-"
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VQRIwfLGS4-"
   },
   "source": [
    "## Actividades\n",
    "\n",
    "1. Implementar y ejecutar el algoritmo SARSA en \"The Cliff\".\n",
    "\n",
    "2. Implementar y ejecutar el algoritmo Q-Learning en \"The Cliff\". ¿Cómo converge con respecto a SARSA? ¿A qué se debe? Comentar.\n",
    "\n",
    "3. Ejecutando con distintos híper-parámetros, realizar una breve descripción sobre cómo afectan a la convergencia los distintos valores de $\\alpha$, $\\epsilon$ y $\\gamma$.\n",
    "\n",
    "4. (Opcional) Implementar política de exploración Softmax, en donde cada acción tiene una probabilidad $$\\pi(a \\mid s) = \\frac{e^{Q(s,a)/\\tau}}{\\sum_{\\widetilde{a} \\in A}e^{Q(s,\\widetilde{a})/\\tau}}$$\n",
    "\n",
    "\n",
    "\n",
    "Para dejar el lab listo para su corrección, dejar link a repo de Github con un notebook ejecutando el agente en la planilla enviada en Slack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIN"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "include_colab_link": true,
   "name": "lab_1_intro_rl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
